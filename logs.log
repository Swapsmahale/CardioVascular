2023-08-13 15:54:39,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 15:54:39,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 15:54:39,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 15:54:39,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-13 15:54:40,222:INFO:PyCaret ClassificationExperiment
2023-08-13 15:54:40,222:INFO:Logging name: clf-default-name
2023-08-13 15:54:40,222:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-13 15:54:40,222:INFO:version 3.0.4
2023-08-13 15:54:40,222:INFO:Initializing setup()
2023-08-13 15:54:40,222:INFO:self.USI: 9441
2023-08-13 15:54:40,222:INFO:self._variable_keys: {'fold_groups_param', 'data', 'log_plots_param', 'fold_generator', 'exp_name_log', 'target_param', 'USI', 'fold_shuffle_param', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'y_test', 'logging_param', 'pipeline', 'html_param', 'idx', 'memory', 'fix_imbalance', 'y', 'X', 'is_multiclass', 'X_test', 'exp_id', '_available_plots', 'n_jobs_param', '_ml_usecase', 'seed', 'X_train'}
2023-08-13 15:54:40,222:INFO:Checking environment
2023-08-13 15:54:40,222:INFO:python_version: 3.10.9
2023-08-13 15:54:40,222:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-08-13 15:54:40,222:INFO:machine: AMD64
2023-08-13 15:54:40,222:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-13 15:54:40,222:INFO:Memory: svmem(total=4021411840, available=465989632, percent=88.4, used=3555422208, free=465989632)
2023-08-13 15:54:40,222:INFO:Physical Core: 2
2023-08-13 15:54:40,222:INFO:Logical Core: 4
2023-08-13 15:54:40,222:INFO:Checking libraries
2023-08-13 15:54:40,222:INFO:System:
2023-08-13 15:54:40,222:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-08-13 15:54:40,222:INFO:executable: C:\Users\91772\anaconda3\python.exe
2023-08-13 15:54:40,225:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-13 15:54:40,225:INFO:PyCaret required dependencies:
2023-08-13 15:54:42,285:INFO:                 pip: 22.3.1
2023-08-13 15:54:42,285:INFO:          setuptools: 65.6.3
2023-08-13 15:54:42,285:INFO:             pycaret: 3.0.4
2023-08-13 15:54:42,285:INFO:             IPython: 8.10.0
2023-08-13 15:54:42,285:INFO:          ipywidgets: 7.6.5
2023-08-13 15:54:42,285:INFO:                tqdm: 4.64.1
2023-08-13 15:54:42,285:INFO:               numpy: 1.23.5
2023-08-13 15:54:42,285:INFO:              pandas: 1.5.3
2023-08-13 15:54:42,285:INFO:              jinja2: 3.1.2
2023-08-13 15:54:42,285:INFO:               scipy: 1.10.0
2023-08-13 15:54:42,285:INFO:              joblib: 1.3.1
2023-08-13 15:54:42,285:INFO:             sklearn: 1.2.1
2023-08-13 15:54:42,285:INFO:                pyod: 1.1.0
2023-08-13 15:54:42,285:INFO:            imblearn: 0.10.1
2023-08-13 15:54:42,285:INFO:   category_encoders: 2.6.1
2023-08-13 15:54:42,285:INFO:            lightgbm: 4.0.0
2023-08-13 15:54:42,285:INFO:               numba: 0.56.4
2023-08-13 15:54:42,285:INFO:            requests: 2.28.1
2023-08-13 15:54:42,285:INFO:          matplotlib: 3.7.0
2023-08-13 15:54:42,285:INFO:          scikitplot: 0.3.7
2023-08-13 15:54:42,285:INFO:         yellowbrick: 1.5
2023-08-13 15:54:42,285:INFO:              plotly: 5.9.0
2023-08-13 15:54:42,285:INFO:    plotly-resampler: Not installed
2023-08-13 15:54:42,285:INFO:             kaleido: 0.2.1
2023-08-13 15:54:42,285:INFO:           schemdraw: 0.15
2023-08-13 15:54:42,285:INFO:         statsmodels: 0.13.5
2023-08-13 15:54:42,285:INFO:              sktime: 0.20.1
2023-08-13 15:54:42,285:INFO:               tbats: 1.1.3
2023-08-13 15:54:42,285:INFO:            pmdarima: 2.0.3
2023-08-13 15:54:42,285:INFO:              psutil: 5.9.0
2023-08-13 15:54:42,285:INFO:          markupsafe: 2.1.1
2023-08-13 15:54:42,285:INFO:             pickle5: Not installed
2023-08-13 15:54:42,285:INFO:         cloudpickle: 2.0.0
2023-08-13 15:54:42,285:INFO:         deprecation: 2.1.0
2023-08-13 15:54:42,285:INFO:              xxhash: 3.2.0
2023-08-13 15:54:42,285:INFO:           wurlitzer: Not installed
2023-08-13 15:54:42,285:INFO:PyCaret optional dependencies:
2023-08-13 15:54:42,299:INFO:                shap: Not installed
2023-08-13 15:54:42,299:INFO:           interpret: Not installed
2023-08-13 15:54:42,299:INFO:                umap: Not installed
2023-08-13 15:54:42,299:INFO:    pandas_profiling: 4.3.1
2023-08-13 15:54:42,299:INFO:  explainerdashboard: Not installed
2023-08-13 15:54:42,299:INFO:             autoviz: Not installed
2023-08-13 15:54:42,299:INFO:           fairlearn: Not installed
2023-08-13 15:54:42,299:INFO:          deepchecks: Not installed
2023-08-13 15:54:42,299:INFO:             xgboost: Not installed
2023-08-13 15:54:42,299:INFO:            catboost: Not installed
2023-08-13 15:54:42,299:INFO:              kmodes: Not installed
2023-08-13 15:54:42,299:INFO:             mlxtend: Not installed
2023-08-13 15:54:42,299:INFO:       statsforecast: Not installed
2023-08-13 15:54:42,299:INFO:        tune_sklearn: Not installed
2023-08-13 15:54:42,299:INFO:                 ray: Not installed
2023-08-13 15:54:42,299:INFO:            hyperopt: Not installed
2023-08-13 15:54:42,299:INFO:              optuna: Not installed
2023-08-13 15:54:42,299:INFO:               skopt: Not installed
2023-08-13 15:54:42,299:INFO:              mlflow: Not installed
2023-08-13 15:54:42,299:INFO:              gradio: Not installed
2023-08-13 15:54:42,299:INFO:             fastapi: Not installed
2023-08-13 15:54:42,299:INFO:             uvicorn: Not installed
2023-08-13 15:54:42,299:INFO:              m2cgen: Not installed
2023-08-13 15:54:42,299:INFO:           evidently: Not installed
2023-08-13 15:54:42,299:INFO:               fugue: Not installed
2023-08-13 15:54:42,299:INFO:           streamlit: Not installed
2023-08-13 15:54:42,299:INFO:             prophet: Not installed
2023-08-13 15:54:42,299:INFO:None
2023-08-13 15:54:42,299:INFO:Set up data.
2023-08-13 15:54:42,472:INFO:Set up train/test split.
2023-08-13 15:54:42,707:INFO:Set up index.
2023-08-13 15:54:42,723:INFO:Set up folding strategy.
2023-08-13 15:54:42,723:INFO:Assigning column types.
2023-08-13 15:54:42,838:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-13 15:54:42,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 15:54:42,911:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:54:42,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:42,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 15:54:43,049:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:54:43,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-13 15:54:43,163:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:54:43,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,262:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:54:43,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,305:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-13 15:54:43,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:43,494:INFO:Preparing preprocessing pipeline...
2023-08-13 15:54:43,526:INFO:Set up simple imputation.
2023-08-13 15:54:43,699:INFO:Finished creating preprocessing pipeline.
2023-08-13 15:54:43,716:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-08-13 15:54:43,716:INFO:Creating final display dataframe.
2023-08-13 15:54:44,204:INFO:Setup _display_container:                     Description             Value
0                    Session id              6404
1                        Target     Heart_Disease
2                   Target type            Binary
3           Original data shape      (308854, 17)
4        Transformed data shape      (308854, 17)
5   Transformed train set shape      (216197, 17)
6    Transformed test set shape       (92657, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9441
2023-08-13 15:54:44,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:44,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:44,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:44,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:54:44,393:INFO:setup() successfully completed in 4.56s...............
2023-08-13 15:58:31,535:INFO:PyCaret ClassificationExperiment
2023-08-13 15:58:31,535:INFO:Logging name: clf-default-name
2023-08-13 15:58:31,535:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-13 15:58:31,535:INFO:version 3.0.4
2023-08-13 15:58:31,535:INFO:Initializing setup()
2023-08-13 15:58:31,535:INFO:self.USI: e32c
2023-08-13 15:58:31,535:INFO:self._variable_keys: {'fold_groups_param', 'data', 'log_plots_param', 'fold_generator', 'exp_name_log', 'target_param', 'USI', 'fold_shuffle_param', 'gpu_n_jobs_param', 'gpu_param', 'y_train', 'y_test', 'logging_param', 'pipeline', 'html_param', 'idx', 'memory', 'fix_imbalance', 'y', 'X', 'is_multiclass', 'X_test', 'exp_id', '_available_plots', 'n_jobs_param', '_ml_usecase', 'seed', 'X_train'}
2023-08-13 15:58:31,535:INFO:Checking environment
2023-08-13 15:58:31,535:INFO:python_version: 3.10.9
2023-08-13 15:58:31,535:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2023-08-13 15:58:31,536:INFO:machine: AMD64
2023-08-13 15:58:31,536:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-13 15:58:31,537:INFO:Memory: svmem(total=4021411840, available=546230272, percent=86.4, used=3475181568, free=546230272)
2023-08-13 15:58:31,537:INFO:Physical Core: 2
2023-08-13 15:58:31,537:INFO:Logical Core: 4
2023-08-13 15:58:31,537:INFO:Checking libraries
2023-08-13 15:58:31,537:INFO:System:
2023-08-13 15:58:31,537:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2023-08-13 15:58:31,537:INFO:executable: C:\Users\91772\anaconda3\python.exe
2023-08-13 15:58:31,537:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-13 15:58:31,538:INFO:PyCaret required dependencies:
2023-08-13 15:58:31,538:INFO:                 pip: 22.3.1
2023-08-13 15:58:31,538:INFO:          setuptools: 65.6.3
2023-08-13 15:58:31,538:INFO:             pycaret: 3.0.4
2023-08-13 15:58:31,538:INFO:             IPython: 8.10.0
2023-08-13 15:58:31,538:INFO:          ipywidgets: 7.6.5
2023-08-13 15:58:31,538:INFO:                tqdm: 4.64.1
2023-08-13 15:58:31,538:INFO:               numpy: 1.23.5
2023-08-13 15:58:31,538:INFO:              pandas: 1.5.3
2023-08-13 15:58:31,538:INFO:              jinja2: 3.1.2
2023-08-13 15:58:31,538:INFO:               scipy: 1.10.0
2023-08-13 15:58:31,538:INFO:              joblib: 1.3.1
2023-08-13 15:58:31,538:INFO:             sklearn: 1.2.1
2023-08-13 15:58:31,538:INFO:                pyod: 1.1.0
2023-08-13 15:58:31,538:INFO:            imblearn: 0.10.1
2023-08-13 15:58:31,538:INFO:   category_encoders: 2.6.1
2023-08-13 15:58:31,538:INFO:            lightgbm: 4.0.0
2023-08-13 15:58:31,538:INFO:               numba: 0.56.4
2023-08-13 15:58:31,538:INFO:            requests: 2.28.1
2023-08-13 15:58:31,538:INFO:          matplotlib: 3.7.0
2023-08-13 15:58:31,538:INFO:          scikitplot: 0.3.7
2023-08-13 15:58:31,538:INFO:         yellowbrick: 1.5
2023-08-13 15:58:31,539:INFO:              plotly: 5.9.0
2023-08-13 15:58:31,539:INFO:    plotly-resampler: Not installed
2023-08-13 15:58:31,539:INFO:             kaleido: 0.2.1
2023-08-13 15:58:31,539:INFO:           schemdraw: 0.15
2023-08-13 15:58:31,539:INFO:         statsmodels: 0.13.5
2023-08-13 15:58:31,539:INFO:              sktime: 0.20.1
2023-08-13 15:58:31,539:INFO:               tbats: 1.1.3
2023-08-13 15:58:31,539:INFO:            pmdarima: 2.0.3
2023-08-13 15:58:31,539:INFO:              psutil: 5.9.0
2023-08-13 15:58:31,539:INFO:          markupsafe: 2.1.1
2023-08-13 15:58:31,539:INFO:             pickle5: Not installed
2023-08-13 15:58:31,539:INFO:         cloudpickle: 2.0.0
2023-08-13 15:58:31,539:INFO:         deprecation: 2.1.0
2023-08-13 15:58:31,539:INFO:              xxhash: 3.2.0
2023-08-13 15:58:31,539:INFO:           wurlitzer: Not installed
2023-08-13 15:58:31,539:INFO:PyCaret optional dependencies:
2023-08-13 15:58:31,539:INFO:                shap: Not installed
2023-08-13 15:58:31,539:INFO:           interpret: Not installed
2023-08-13 15:58:31,539:INFO:                umap: Not installed
2023-08-13 15:58:31,539:INFO:    pandas_profiling: 4.3.1
2023-08-13 15:58:31,539:INFO:  explainerdashboard: Not installed
2023-08-13 15:58:31,539:INFO:             autoviz: Not installed
2023-08-13 15:58:31,540:INFO:           fairlearn: Not installed
2023-08-13 15:58:31,540:INFO:          deepchecks: Not installed
2023-08-13 15:58:31,540:INFO:             xgboost: Not installed
2023-08-13 15:58:31,540:INFO:            catboost: Not installed
2023-08-13 15:58:31,540:INFO:              kmodes: Not installed
2023-08-13 15:58:31,540:INFO:             mlxtend: Not installed
2023-08-13 15:58:31,540:INFO:       statsforecast: Not installed
2023-08-13 15:58:31,540:INFO:        tune_sklearn: Not installed
2023-08-13 15:58:31,540:INFO:                 ray: Not installed
2023-08-13 15:58:31,540:INFO:            hyperopt: Not installed
2023-08-13 15:58:31,540:INFO:              optuna: Not installed
2023-08-13 15:58:31,540:INFO:               skopt: Not installed
2023-08-13 15:58:31,540:INFO:              mlflow: Not installed
2023-08-13 15:58:31,540:INFO:              gradio: Not installed
2023-08-13 15:58:31,540:INFO:             fastapi: Not installed
2023-08-13 15:58:31,540:INFO:             uvicorn: Not installed
2023-08-13 15:58:31,540:INFO:              m2cgen: Not installed
2023-08-13 15:58:31,540:INFO:           evidently: Not installed
2023-08-13 15:58:31,540:INFO:               fugue: Not installed
2023-08-13 15:58:31,540:INFO:           streamlit: Not installed
2023-08-13 15:58:31,540:INFO:             prophet: Not installed
2023-08-13 15:58:31,540:INFO:None
2023-08-13 15:58:31,540:INFO:Set up data.
2023-08-13 15:58:31,668:INFO:Set up train/test split.
2023-08-13 15:58:31,825:INFO:Set up index.
2023-08-13 15:58:31,840:INFO:Set up folding strategy.
2023-08-13 15:58:31,840:INFO:Assigning column types.
2023-08-13 15:58:31,928:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-13 15:58:31,969:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 15:58:31,969:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:58:31,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:31,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-13 15:58:32,047:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:58:32,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,069:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-13 15:58:32,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:58:32,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-13 15:58:32,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-13 15:58:32,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:32,385:INFO:Preparing preprocessing pipeline...
2023-08-13 15:58:32,385:INFO:Set up simple imputation.
2023-08-13 15:58:32,385:INFO:Set up imbalanced handling.
2023-08-13 15:58:32,602:INFO:Finished creating preprocessing pipeline.
2023-08-13 15:58:32,617:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2023-08-13 15:58:32,617:INFO:Creating final display dataframe.
2023-08-13 15:58:35,820:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target     Heart_Disease
2                   Target type            Binary
3           Original data shape      (308854, 17)
4        Transformed data shape      (490091, 17)
5   Transformed train set shape      (397434, 17)
6    Transformed test set shape       (92657, 17)
7              Numeric features                16
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             SMOTE
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e32c
2023-08-13 15:58:35,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:35,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:35,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:35,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-13 15:58:35,994:INFO:setup() successfully completed in 4.69s...............
2023-08-13 15:58:55,428:INFO:Initializing compare_models()
2023-08-13 15:58:55,428:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-13 15:58:55,429:INFO:Checking exceptions
2023-08-13 15:58:55,558:INFO:Preparing display monitor
2023-08-13 15:58:55,627:INFO:Initializing Logistic Regression
2023-08-13 15:58:55,627:INFO:Total runtime is 0.0 minutes
2023-08-13 15:58:55,633:INFO:SubProcess create_model() called ==================================
2023-08-13 15:58:55,636:INFO:Initializing create_model()
2023-08-13 15:58:55,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 15:58:55,636:INFO:Checking exceptions
2023-08-13 15:58:55,636:INFO:Importing libraries
2023-08-13 15:58:55,637:INFO:Copying training dataset
2023-08-13 15:58:55,800:INFO:Defining folds
2023-08-13 15:58:55,800:INFO:Declaring metric variables
2023-08-13 15:58:55,810:INFO:Importing untrained model
2023-08-13 15:58:55,810:INFO:Logistic Regression Imported successfully
2023-08-13 15:58:55,832:INFO:Starting cross validation
2023-08-13 15:58:55,835:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 15:59:52,163:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 15:59:52,241:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 15:59:52,995:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 15:59:53,092:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:00:43,315:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:00:43,960:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:00:44,054:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:00:44,366:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:01:16,560:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:01:17,097:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-13 16:01:17,339:INFO:Calculating mean and std
2023-08-13 16:01:17,340:INFO:Creating metrics dataframe
2023-08-13 16:01:17,613:INFO:Uploading results into container
2023-08-13 16:01:17,613:INFO:Uploading model into container now
2023-08-13 16:01:17,624:INFO:_master_model_container: 1
2023-08-13 16:01:17,624:INFO:_display_container: 2
2023-08-13 16:01:17,626:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-13 16:01:17,626:INFO:create_model() successfully completed......................................
2023-08-13 16:01:18,677:INFO:SubProcess create_model() end ==================================
2023-08-13 16:01:18,677:INFO:Creating metrics dataframe
2023-08-13 16:01:18,698:INFO:Initializing K Neighbors Classifier
2023-08-13 16:01:18,698:INFO:Total runtime is 2.384522847334544 minutes
2023-08-13 16:01:18,700:INFO:SubProcess create_model() called ==================================
2023-08-13 16:01:18,703:INFO:Initializing create_model()
2023-08-13 16:01:18,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:01:18,703:INFO:Checking exceptions
2023-08-13 16:01:18,703:INFO:Importing libraries
2023-08-13 16:01:18,703:INFO:Copying training dataset
2023-08-13 16:01:18,857:INFO:Defining folds
2023-08-13 16:01:18,857:INFO:Declaring metric variables
2023-08-13 16:01:18,868:INFO:Importing untrained model
2023-08-13 16:01:18,868:INFO:K Neighbors Classifier Imported successfully
2023-08-13 16:01:18,885:INFO:Starting cross validation
2023-08-13 16:01:18,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:06:58,270:INFO:Calculating mean and std
2023-08-13 16:06:58,272:INFO:Creating metrics dataframe
2023-08-13 16:06:58,588:INFO:Uploading results into container
2023-08-13 16:06:58,588:INFO:Uploading model into container now
2023-08-13 16:06:58,598:INFO:_master_model_container: 2
2023-08-13 16:06:58,598:INFO:_display_container: 2
2023-08-13 16:06:58,598:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-13 16:06:58,598:INFO:create_model() successfully completed......................................
2023-08-13 16:06:59,003:INFO:SubProcess create_model() end ==================================
2023-08-13 16:06:59,003:INFO:Creating metrics dataframe
2023-08-13 16:06:59,019:INFO:Initializing Naive Bayes
2023-08-13 16:06:59,019:INFO:Total runtime is 8.056534469127655 minutes
2023-08-13 16:06:59,038:INFO:SubProcess create_model() called ==================================
2023-08-13 16:06:59,039:INFO:Initializing create_model()
2023-08-13 16:06:59,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:06:59,039:INFO:Checking exceptions
2023-08-13 16:06:59,039:INFO:Importing libraries
2023-08-13 16:06:59,039:INFO:Copying training dataset
2023-08-13 16:06:59,286:INFO:Defining folds
2023-08-13 16:06:59,286:INFO:Declaring metric variables
2023-08-13 16:06:59,301:INFO:Importing untrained model
2023-08-13 16:06:59,315:INFO:Naive Bayes Imported successfully
2023-08-13 16:06:59,329:INFO:Starting cross validation
2023-08-13 16:06:59,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:07:03,783:INFO:Calculating mean and std
2023-08-13 16:07:03,789:INFO:Creating metrics dataframe
2023-08-13 16:07:04,030:INFO:Uploading results into container
2023-08-13 16:07:04,032:INFO:Uploading model into container now
2023-08-13 16:07:04,032:INFO:_master_model_container: 3
2023-08-13 16:07:04,032:INFO:_display_container: 2
2023-08-13 16:07:04,033:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-13 16:07:04,033:INFO:create_model() successfully completed......................................
2023-08-13 16:07:04,301:INFO:SubProcess create_model() end ==================================
2023-08-13 16:07:04,301:INFO:Creating metrics dataframe
2023-08-13 16:07:04,351:INFO:Initializing Decision Tree Classifier
2023-08-13 16:07:04,351:INFO:Total runtime is 8.14540999730428 minutes
2023-08-13 16:07:04,359:INFO:SubProcess create_model() called ==================================
2023-08-13 16:07:04,360:INFO:Initializing create_model()
2023-08-13 16:07:04,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:07:04,360:INFO:Checking exceptions
2023-08-13 16:07:04,360:INFO:Importing libraries
2023-08-13 16:07:04,360:INFO:Copying training dataset
2023-08-13 16:07:04,504:INFO:Defining folds
2023-08-13 16:07:04,504:INFO:Declaring metric variables
2023-08-13 16:07:04,514:INFO:Importing untrained model
2023-08-13 16:07:04,514:INFO:Decision Tree Classifier Imported successfully
2023-08-13 16:07:04,536:INFO:Starting cross validation
2023-08-13 16:07:04,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:07:18,572:INFO:Calculating mean and std
2023-08-13 16:07:18,575:INFO:Creating metrics dataframe
2023-08-13 16:07:18,834:INFO:Uploading results into container
2023-08-13 16:07:18,834:INFO:Uploading model into container now
2023-08-13 16:07:18,847:INFO:_master_model_container: 4
2023-08-13 16:07:18,847:INFO:_display_container: 2
2023-08-13 16:07:18,847:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-08-13 16:07:18,849:INFO:create_model() successfully completed......................................
2023-08-13 16:07:19,121:INFO:SubProcess create_model() end ==================================
2023-08-13 16:07:19,121:INFO:Creating metrics dataframe
2023-08-13 16:07:19,136:INFO:Initializing SVM - Linear Kernel
2023-08-13 16:07:19,136:INFO:Total runtime is 8.391820295651755 minutes
2023-08-13 16:07:19,142:INFO:SubProcess create_model() called ==================================
2023-08-13 16:07:19,142:INFO:Initializing create_model()
2023-08-13 16:07:19,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:07:19,142:INFO:Checking exceptions
2023-08-13 16:07:19,142:INFO:Importing libraries
2023-08-13 16:07:19,142:INFO:Copying training dataset
2023-08-13 16:07:19,293:INFO:Defining folds
2023-08-13 16:07:19,293:INFO:Declaring metric variables
2023-08-13 16:07:19,303:INFO:Importing untrained model
2023-08-13 16:07:19,311:INFO:SVM - Linear Kernel Imported successfully
2023-08-13 16:07:19,317:INFO:Starting cross validation
2023-08-13 16:07:19,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:07:39,049:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:07:39,471:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:07:40,114:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:07:42,061:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:07:58,633:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:00,230:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:03,018:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:03,347:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:14,980:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:16,290:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-13 16:08:16,461:INFO:Calculating mean and std
2023-08-13 16:08:16,461:INFO:Creating metrics dataframe
2023-08-13 16:08:16,789:INFO:Uploading results into container
2023-08-13 16:08:16,789:INFO:Uploading model into container now
2023-08-13 16:08:16,800:INFO:_master_model_container: 5
2023-08-13 16:08:16,800:INFO:_display_container: 2
2023-08-13 16:08:16,805:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-13 16:08:16,805:INFO:create_model() successfully completed......................................
2023-08-13 16:08:17,107:INFO:SubProcess create_model() end ==================================
2023-08-13 16:08:17,107:INFO:Creating metrics dataframe
2023-08-13 16:08:17,125:INFO:Initializing Ridge Classifier
2023-08-13 16:08:17,131:INFO:Total runtime is 9.358407203356427 minutes
2023-08-13 16:08:17,133:INFO:SubProcess create_model() called ==================================
2023-08-13 16:08:17,135:INFO:Initializing create_model()
2023-08-13 16:08:17,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:08:17,135:INFO:Checking exceptions
2023-08-13 16:08:17,135:INFO:Importing libraries
2023-08-13 16:08:17,135:INFO:Copying training dataset
2023-08-13 16:08:17,322:INFO:Defining folds
2023-08-13 16:08:17,322:INFO:Declaring metric variables
2023-08-13 16:08:17,335:INFO:Importing untrained model
2023-08-13 16:08:17,343:INFO:Ridge Classifier Imported successfully
2023-08-13 16:08:17,356:INFO:Starting cross validation
2023-08-13 16:08:17,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:08:18,121:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:18,136:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:18,136:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:18,183:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:19,503:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:19,555:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:19,570:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:19,619:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:20,628:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:20,690:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-13 16:08:21,645:INFO:Calculating mean and std
2023-08-13 16:08:21,645:INFO:Creating metrics dataframe
2023-08-13 16:08:21,922:INFO:Uploading results into container
2023-08-13 16:08:21,922:INFO:Uploading model into container now
2023-08-13 16:08:21,924:INFO:_master_model_container: 6
2023-08-13 16:08:21,924:INFO:_display_container: 2
2023-08-13 16:08:21,924:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-08-13 16:08:21,924:INFO:create_model() successfully completed......................................
2023-08-13 16:08:22,194:INFO:SubProcess create_model() end ==================================
2023-08-13 16:08:22,195:INFO:Creating metrics dataframe
2023-08-13 16:08:22,210:INFO:Initializing Random Forest Classifier
2023-08-13 16:08:22,216:INFO:Total runtime is 9.443164412180584 minutes
2023-08-13 16:08:22,221:INFO:SubProcess create_model() called ==================================
2023-08-13 16:08:22,222:INFO:Initializing create_model()
2023-08-13 16:08:22,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:08:22,223:INFO:Checking exceptions
2023-08-13 16:08:22,223:INFO:Importing libraries
2023-08-13 16:08:22,223:INFO:Copying training dataset
2023-08-13 16:08:22,380:INFO:Defining folds
2023-08-13 16:08:22,380:INFO:Declaring metric variables
2023-08-13 16:08:22,397:INFO:Importing untrained model
2023-08-13 16:08:22,407:INFO:Random Forest Classifier Imported successfully
2023-08-13 16:08:22,426:INFO:Starting cross validation
2023-08-13 16:08:22,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:10:24,176:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:10:25,387:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:10:25,438:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:10:27,091:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:12:28,561:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:12:29,618:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:13:36,160:INFO:Calculating mean and std
2023-08-13 16:13:36,224:INFO:Creating metrics dataframe
2023-08-13 16:13:36,722:INFO:Uploading results into container
2023-08-13 16:13:36,722:INFO:Uploading model into container now
2023-08-13 16:13:36,738:INFO:_master_model_container: 7
2023-08-13 16:13:36,738:INFO:_display_container: 2
2023-08-13 16:13:36,755:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-08-13 16:13:36,757:INFO:create_model() successfully completed......................................
2023-08-13 16:13:37,852:INFO:SubProcess create_model() end ==================================
2023-08-13 16:13:37,852:INFO:Creating metrics dataframe
2023-08-13 16:13:37,882:INFO:Initializing Quadratic Discriminant Analysis
2023-08-13 16:13:37,882:INFO:Total runtime is 14.70425186554591 minutes
2023-08-13 16:13:37,895:INFO:SubProcess create_model() called ==================================
2023-08-13 16:13:37,895:INFO:Initializing create_model()
2023-08-13 16:13:37,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:13:37,895:INFO:Checking exceptions
2023-08-13 16:13:37,895:INFO:Importing libraries
2023-08-13 16:13:37,895:INFO:Copying training dataset
2023-08-13 16:13:38,228:INFO:Defining folds
2023-08-13 16:13:38,228:INFO:Declaring metric variables
2023-08-13 16:13:38,245:INFO:Importing untrained model
2023-08-13 16:13:38,257:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-13 16:13:38,279:INFO:Starting cross validation
2023-08-13 16:13:38,292:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:13:46,055:INFO:Calculating mean and std
2023-08-13 16:13:46,058:INFO:Creating metrics dataframe
2023-08-13 16:13:46,504:INFO:Uploading results into container
2023-08-13 16:13:46,507:INFO:Uploading model into container now
2023-08-13 16:13:46,507:INFO:_master_model_container: 8
2023-08-13 16:13:46,509:INFO:_display_container: 2
2023-08-13 16:13:46,509:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-13 16:13:46,509:INFO:create_model() successfully completed......................................
2023-08-13 16:13:46,849:INFO:SubProcess create_model() end ==================================
2023-08-13 16:13:46,849:INFO:Creating metrics dataframe
2023-08-13 16:13:46,886:INFO:Initializing Ada Boost Classifier
2023-08-13 16:13:46,886:INFO:Total runtime is 14.854324503739676 minutes
2023-08-13 16:13:46,893:INFO:SubProcess create_model() called ==================================
2023-08-13 16:13:46,894:INFO:Initializing create_model()
2023-08-13 16:13:46,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:13:46,894:INFO:Checking exceptions
2023-08-13 16:13:46,894:INFO:Importing libraries
2023-08-13 16:13:46,894:INFO:Copying training dataset
2023-08-13 16:13:47,123:INFO:Defining folds
2023-08-13 16:13:47,123:INFO:Declaring metric variables
2023-08-13 16:13:47,138:INFO:Importing untrained model
2023-08-13 16:13:47,147:INFO:Ada Boost Classifier Imported successfully
2023-08-13 16:13:47,151:INFO:Starting cross validation
2023-08-13 16:13:47,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:15:53,943:INFO:Calculating mean and std
2023-08-13 16:15:53,943:INFO:Creating metrics dataframe
2023-08-13 16:15:54,385:INFO:Uploading results into container
2023-08-13 16:15:54,385:INFO:Uploading model into container now
2023-08-13 16:15:54,385:INFO:_master_model_container: 9
2023-08-13 16:15:54,385:INFO:_display_container: 2
2023-08-13 16:15:54,398:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-08-13 16:15:54,398:INFO:create_model() successfully completed......................................
2023-08-13 16:15:54,728:INFO:SubProcess create_model() end ==================================
2023-08-13 16:15:54,728:INFO:Creating metrics dataframe
2023-08-13 16:15:54,751:INFO:Initializing Gradient Boosting Classifier
2023-08-13 16:15:54,753:INFO:Total runtime is 16.98543407917023 minutes
2023-08-13 16:15:54,758:INFO:SubProcess create_model() called ==================================
2023-08-13 16:15:54,759:INFO:Initializing create_model()
2023-08-13 16:15:54,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:15:54,759:INFO:Checking exceptions
2023-08-13 16:15:54,760:INFO:Importing libraries
2023-08-13 16:15:54,760:INFO:Copying training dataset
2023-08-13 16:15:55,013:INFO:Defining folds
2023-08-13 16:15:55,013:INFO:Declaring metric variables
2023-08-13 16:15:55,021:INFO:Importing untrained model
2023-08-13 16:15:55,029:INFO:Gradient Boosting Classifier Imported successfully
2023-08-13 16:15:55,044:INFO:Starting cross validation
2023-08-13 16:15:55,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:29:39,678:INFO:Calculating mean and std
2023-08-13 16:29:39,720:INFO:Creating metrics dataframe
2023-08-13 16:29:40,103:INFO:Uploading results into container
2023-08-13 16:29:40,107:INFO:Uploading model into container now
2023-08-13 16:29:40,111:INFO:_master_model_container: 10
2023-08-13 16:29:40,113:INFO:_display_container: 2
2023-08-13 16:29:40,115:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-13 16:29:40,115:INFO:create_model() successfully completed......................................
2023-08-13 16:29:40,816:INFO:SubProcess create_model() end ==================================
2023-08-13 16:29:40,816:INFO:Creating metrics dataframe
2023-08-13 16:29:40,843:INFO:Initializing Linear Discriminant Analysis
2023-08-13 16:29:40,843:INFO:Total runtime is 30.75361546278 minutes
2023-08-13 16:29:40,843:INFO:SubProcess create_model() called ==================================
2023-08-13 16:29:40,843:INFO:Initializing create_model()
2023-08-13 16:29:40,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:29:40,843:INFO:Checking exceptions
2023-08-13 16:29:40,849:INFO:Importing libraries
2023-08-13 16:29:40,849:INFO:Copying training dataset
2023-08-13 16:29:41,065:INFO:Defining folds
2023-08-13 16:29:41,065:INFO:Declaring metric variables
2023-08-13 16:29:41,072:INFO:Importing untrained model
2023-08-13 16:29:41,081:INFO:Linear Discriminant Analysis Imported successfully
2023-08-13 16:29:41,095:INFO:Starting cross validation
2023-08-13 16:29:41,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:29:52,517:INFO:Calculating mean and std
2023-08-13 16:29:52,517:INFO:Creating metrics dataframe
2023-08-13 16:29:52,852:INFO:Uploading results into container
2023-08-13 16:29:52,852:INFO:Uploading model into container now
2023-08-13 16:29:52,852:INFO:_master_model_container: 11
2023-08-13 16:29:52,852:INFO:_display_container: 2
2023-08-13 16:29:52,852:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-13 16:29:52,859:INFO:create_model() successfully completed......................................
2023-08-13 16:29:53,128:INFO:SubProcess create_model() end ==================================
2023-08-13 16:29:53,128:INFO:Creating metrics dataframe
2023-08-13 16:29:53,144:INFO:Initializing Extra Trees Classifier
2023-08-13 16:29:53,144:INFO:Total runtime is 30.95863034327825 minutes
2023-08-13 16:29:53,160:INFO:SubProcess create_model() called ==================================
2023-08-13 16:29:53,161:INFO:Initializing create_model()
2023-08-13 16:29:53,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:29:53,161:INFO:Checking exceptions
2023-08-13 16:29:53,161:INFO:Importing libraries
2023-08-13 16:29:53,161:INFO:Copying training dataset
2023-08-13 16:29:53,315:INFO:Defining folds
2023-08-13 16:29:53,316:INFO:Declaring metric variables
2023-08-13 16:29:53,319:INFO:Importing untrained model
2023-08-13 16:29:53,325:INFO:Extra Trees Classifier Imported successfully
2023-08-13 16:29:53,340:INFO:Starting cross validation
2023-08-13 16:29:53,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:32:51,305:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:33:05,921:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 6.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:33:06,323:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 6.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:33:09,275:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:33:10,613:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.33s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:33:13,865:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 14.22s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:33:16,363:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-13 16:33:19,088:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:33:34,111:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-13 16:36:16,012:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 11.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:36:20,318:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 12.05s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:36:22,213:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 11.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:36:35,777:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 8.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:36:36,744:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 24.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-13 16:36:40,070:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 9.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:36:41,183:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 9.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:37:12,395:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-13 16:37:32,195:WARNING:C:\Users\91772\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 19.30s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-13 16:38:26,557:INFO:Calculating mean and std
2023-08-13 16:38:26,658:INFO:Creating metrics dataframe
2023-08-13 16:38:27,106:INFO:Uploading results into container
2023-08-13 16:38:27,106:INFO:Uploading model into container now
2023-08-13 16:38:27,115:INFO:_master_model_container: 12
2023-08-13 16:38:27,115:INFO:_display_container: 2
2023-08-13 16:38:27,125:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-08-13 16:38:27,125:INFO:create_model() successfully completed......................................
2023-08-13 16:38:27,923:INFO:SubProcess create_model() end ==================================
2023-08-13 16:38:27,923:INFO:Creating metrics dataframe
2023-08-13 16:38:27,944:INFO:Initializing Light Gradient Boosting Machine
2023-08-13 16:38:27,947:INFO:Total runtime is 39.53867838780086 minutes
2023-08-13 16:38:27,948:INFO:SubProcess create_model() called ==================================
2023-08-13 16:38:27,952:INFO:Initializing create_model()
2023-08-13 16:38:27,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:38:27,952:INFO:Checking exceptions
2023-08-13 16:38:27,952:INFO:Importing libraries
2023-08-13 16:38:27,952:INFO:Copying training dataset
2023-08-13 16:38:28,222:INFO:Defining folds
2023-08-13 16:38:28,222:INFO:Declaring metric variables
2023-08-13 16:38:28,231:INFO:Importing untrained model
2023-08-13 16:38:28,231:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:38:28,253:INFO:Starting cross validation
2023-08-13 16:38:28,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:38:58,336:INFO:Calculating mean and std
2023-08-13 16:38:58,338:INFO:Creating metrics dataframe
2023-08-13 16:38:58,736:INFO:Uploading results into container
2023-08-13 16:38:58,736:INFO:Uploading model into container now
2023-08-13 16:38:58,736:INFO:_master_model_container: 13
2023-08-13 16:38:58,741:INFO:_display_container: 2
2023-08-13 16:38:58,741:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:38:58,741:INFO:create_model() successfully completed......................................
2023-08-13 16:38:59,053:INFO:SubProcess create_model() end ==================================
2023-08-13 16:38:59,053:INFO:Creating metrics dataframe
2023-08-13 16:38:59,067:INFO:Initializing Dummy Classifier
2023-08-13 16:38:59,067:INFO:Total runtime is 40.05734256505966 minutes
2023-08-13 16:38:59,086:INFO:SubProcess create_model() called ==================================
2023-08-13 16:38:59,086:INFO:Initializing create_model()
2023-08-13 16:38:59,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000255530079A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:38:59,087:INFO:Checking exceptions
2023-08-13 16:38:59,087:INFO:Importing libraries
2023-08-13 16:38:59,087:INFO:Copying training dataset
2023-08-13 16:38:59,277:INFO:Defining folds
2023-08-13 16:38:59,277:INFO:Declaring metric variables
2023-08-13 16:38:59,277:INFO:Importing untrained model
2023-08-13 16:38:59,298:INFO:Dummy Classifier Imported successfully
2023-08-13 16:38:59,314:INFO:Starting cross validation
2023-08-13 16:38:59,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:38:59,809:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:38:59,825:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:38:59,887:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:38:59,925:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:00,663:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:00,873:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:00,954:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:01,155:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:01,665:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:01,835:WARNING:C:\Users\91772\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-13 16:39:03,703:INFO:Calculating mean and std
2023-08-13 16:39:03,703:INFO:Creating metrics dataframe
2023-08-13 16:39:04,141:INFO:Uploading results into container
2023-08-13 16:39:04,142:INFO:Uploading model into container now
2023-08-13 16:39:04,143:INFO:_master_model_container: 14
2023-08-13 16:39:04,143:INFO:_display_container: 2
2023-08-13 16:39:04,144:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-08-13 16:39:04,144:INFO:create_model() successfully completed......................................
2023-08-13 16:39:04,460:INFO:SubProcess create_model() end ==================================
2023-08-13 16:39:04,460:INFO:Creating metrics dataframe
2023-08-13 16:39:04,497:INFO:Initializing create_model()
2023-08-13 16:39:04,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:39:04,497:INFO:Checking exceptions
2023-08-13 16:39:04,504:INFO:Importing libraries
2023-08-13 16:39:04,504:INFO:Copying training dataset
2023-08-13 16:39:04,705:INFO:Defining folds
2023-08-13 16:39:04,705:INFO:Declaring metric variables
2023-08-13 16:39:04,705:INFO:Importing untrained model
2023-08-13 16:39:04,705:INFO:Declaring custom model
2023-08-13 16:39:04,707:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:39:04,707:INFO:Cross validation set to False
2023-08-13 16:39:04,707:INFO:Fitting Model
2023-08-13 16:39:06,685:INFO:[LightGBM] [Info] Number of positive: 198717, number of negative: 198717
2023-08-13 16:39:06,747:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022186 seconds.
2023-08-13 16:39:06,747:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-13 16:39:06,747:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-13 16:39:06,761:INFO:[LightGBM] [Info] Total Bins 4079
2023-08-13 16:39:06,761:INFO:[LightGBM] [Info] Number of data points in the train set: 397434, number of used features: 16
2023-08-13 16:39:06,763:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-08-13 16:39:10,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:39:10,047:INFO:create_model() successfully completed......................................
2023-08-13 16:39:10,366:INFO:_master_model_container: 14
2023-08-13 16:39:10,367:INFO:_display_container: 2
2023-08-13 16:39:10,369:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:39:10,369:INFO:compare_models() successfully completed......................................
2023-08-13 16:44:01,384:INFO:Initializing create_model()
2023-08-13 16:44:01,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:44:01,385:INFO:Checking exceptions
2023-08-13 16:44:01,466:INFO:Importing libraries
2023-08-13 16:44:01,467:INFO:Copying training dataset
2023-08-13 16:44:01,643:INFO:Defining folds
2023-08-13 16:44:01,643:INFO:Declaring metric variables
2023-08-13 16:44:01,655:INFO:Importing untrained model
2023-08-13 16:44:01,657:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:44:01,680:INFO:Starting cross validation
2023-08-13 16:44:01,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:44:17,067:INFO:Calculating mean and std
2023-08-13 16:44:17,069:INFO:Creating metrics dataframe
2023-08-13 16:44:17,086:INFO:Finalizing model
2023-08-13 16:44:17,568:INFO:Uploading results into container
2023-08-13 16:44:17,578:INFO:Uploading model into container now
2023-08-13 16:44:17,595:INFO:_master_model_container: 15
2023-08-13 16:44:17,595:INFO:_display_container: 3
2023-08-13 16:44:17,595:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:44:17,600:INFO:create_model() successfully completed......................................
2023-08-13 16:46:11,967:INFO:Initializing tune_model()
2023-08-13 16:46:11,967:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>)
2023-08-13 16:46:11,968:INFO:Checking exceptions
2023-08-13 16:46:12,129:INFO:Copying training dataset
2023-08-13 16:46:12,238:INFO:Checking base model
2023-08-13 16:46:12,238:INFO:Base model : Light Gradient Boosting Machine
2023-08-13 16:46:12,238:INFO:Declaring metric variables
2023-08-13 16:46:12,258:INFO:Defining Hyperparameters
2023-08-13 16:46:12,540:INFO:Tuning with n_jobs=-1
2023-08-13 16:46:12,540:INFO:Initializing RandomizedSearchCV
2023-08-13 16:51:28,478:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 86, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.6}
2023-08-13 16:51:28,503:INFO:Hyperparameter search completed
2023-08-13 16:51:28,503:INFO:SubProcess create_model() called ==================================
2023-08-13 16:51:28,503:INFO:Initializing create_model()
2023-08-13 16:51:28,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025553006A10>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.001, 'reg_alpha': 2, 'num_leaves': 40, 'n_estimators': 130, 'min_split_gain': 0.9, 'min_child_samples': 86, 'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.6})
2023-08-13 16:51:28,503:INFO:Checking exceptions
2023-08-13 16:51:28,508:INFO:Importing libraries
2023-08-13 16:51:28,509:INFO:Copying training dataset
2023-08-13 16:51:28,724:INFO:Defining folds
2023-08-13 16:51:28,724:INFO:Declaring metric variables
2023-08-13 16:51:28,744:INFO:Importing untrained model
2023-08-13 16:51:28,746:INFO:Declaring custom model
2023-08-13 16:51:28,752:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:51:28,772:INFO:Starting cross validation
2023-08-13 16:51:28,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:51:34,338:INFO:Calculating mean and std
2023-08-13 16:51:34,338:INFO:Creating metrics dataframe
2023-08-13 16:51:34,349:INFO:Finalizing model
2023-08-13 16:51:34,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-13 16:51:34,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-13 16:51:34,596:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-08-13 16:51:34,900:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-13 16:51:34,900:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-13 16:51:34,900:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-08-13 16:51:34,900:INFO:[LightGBM] [Info] Number of positive: 198717, number of negative: 198717
2023-08-13 16:51:34,947:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033885 seconds.
2023-08-13 16:51:34,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-13 16:51:34,947:INFO:[LightGBM] [Info] Total Bins 4079
2023-08-13 16:51:34,947:INFO:[LightGBM] [Info] Number of data points in the train set: 397434, number of used features: 16
2023-08-13 16:51:34,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-08-13 16:51:39,162:INFO:Uploading results into container
2023-08-13 16:51:39,168:INFO:Uploading model into container now
2023-08-13 16:51:39,171:INFO:_master_model_container: 16
2023-08-13 16:51:39,172:INFO:_display_container: 4
2023-08-13 16:51:39,173:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:51:39,173:INFO:create_model() successfully completed......................................
2023-08-13 16:51:39,634:INFO:SubProcess create_model() end ==================================
2023-08-13 16:51:39,634:INFO:choose_better activated
2023-08-13 16:51:39,650:INFO:SubProcess create_model() called ==================================
2023-08-13 16:51:39,650:INFO:Initializing create_model()
2023-08-13 16:51:39,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-13 16:51:39,650:INFO:Checking exceptions
2023-08-13 16:51:39,657:INFO:Importing libraries
2023-08-13 16:51:39,657:INFO:Copying training dataset
2023-08-13 16:51:39,820:INFO:Defining folds
2023-08-13 16:51:39,820:INFO:Declaring metric variables
2023-08-13 16:51:39,820:INFO:Importing untrained model
2023-08-13 16:51:39,820:INFO:Declaring custom model
2023-08-13 16:51:39,820:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:51:39,820:INFO:Starting cross validation
2023-08-13 16:51:39,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-13 16:51:44,647:INFO:Calculating mean and std
2023-08-13 16:51:44,647:INFO:Creating metrics dataframe
2023-08-13 16:51:44,647:INFO:Finalizing model
2023-08-13 16:51:45,086:INFO:Uploading results into container
2023-08-13 16:51:45,086:INFO:Uploading model into container now
2023-08-13 16:51:45,102:INFO:_master_model_container: 17
2023-08-13 16:51:45,102:INFO:_display_container: 5
2023-08-13 16:51:45,102:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:51:45,102:INFO:create_model() successfully completed......................................
2023-08-13 16:51:45,353:INFO:SubProcess create_model() end ==================================
2023-08-13 16:51:45,369:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9194
2023-08-13 16:51:45,370:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=86, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=130, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=2, reg_lambda=0.001, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9194
2023-08-13 16:51:45,370:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-13 16:51:45,370:INFO:choose_better completed
2023-08-13 16:51:45,370:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-13 16:51:45,390:INFO:_master_model_container: 17
2023-08-13 16:51:45,390:INFO:_display_container: 4
2023-08-13 16:51:45,393:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:51:45,393:INFO:tune_model() successfully completed......................................
2023-08-13 16:54:17,519:INFO:Initializing plot_model()
2023-08-13 16:54:17,519:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, system=True)
2023-08-13 16:54:17,519:INFO:Checking exceptions
2023-08-13 16:54:17,627:INFO:Preloading libraries
2023-08-13 16:54:17,645:INFO:Copying training dataset
2023-08-13 16:54:17,645:INFO:Plot type: auc
2023-08-13 16:54:19,312:INFO:Fitting Model
2023-08-13 16:54:19,312:INFO:Scoring test/hold-out set
2023-08-13 16:54:21,228:INFO:Visual Rendered Successfully
2023-08-13 16:54:21,647:INFO:plot_model() successfully completed......................................
2023-08-13 16:55:28,785:INFO:Initializing evaluate_model()
2023-08-13 16:55:28,786:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-13 16:55:28,920:INFO:Initializing plot_model()
2023-08-13 16:55:28,920:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, system=True)
2023-08-13 16:55:28,920:INFO:Checking exceptions
2023-08-13 16:55:29,005:INFO:Preloading libraries
2023-08-13 16:55:29,014:INFO:Copying training dataset
2023-08-13 16:55:29,014:INFO:Plot type: pipeline
2023-08-13 16:55:29,199:INFO:Visual Rendered Successfully
2023-08-13 16:55:29,357:INFO:plot_model() successfully completed......................................
2023-08-13 16:55:44,026:INFO:Initializing plot_model()
2023-08-13 16:55:44,027:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, system=True)
2023-08-13 16:55:44,027:INFO:Checking exceptions
2023-08-13 16:55:44,073:INFO:Preloading libraries
2023-08-13 16:55:44,089:INFO:Copying training dataset
2023-08-13 16:55:44,089:INFO:Plot type: pr
2023-08-13 16:55:44,544:INFO:Fitting Model
2023-08-13 16:55:44,562:INFO:Scoring test/hold-out set
2023-08-13 16:55:45,202:INFO:Visual Rendered Successfully
2023-08-13 16:55:45,363:INFO:plot_model() successfully completed......................................
2023-08-13 16:55:51,477:INFO:Initializing plot_model()
2023-08-13 16:55:51,478:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, system=True)
2023-08-13 16:55:51,478:INFO:Checking exceptions
2023-08-13 16:55:51,550:INFO:Preloading libraries
2023-08-13 16:55:51,550:INFO:Copying training dataset
2023-08-13 16:55:51,550:INFO:Plot type: auc
2023-08-13 16:55:52,007:INFO:Fitting Model
2023-08-13 16:55:52,022:INFO:Scoring test/hold-out set
2023-08-13 16:55:52,690:INFO:Visual Rendered Successfully
2023-08-13 16:55:52,846:INFO:plot_model() successfully completed......................................
2023-08-13 16:56:19,275:INFO:Initializing predict_model()
2023-08-13 16:56:19,275:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000255539949D0>)
2023-08-13 16:56:19,275:INFO:Checking exceptions
2023-08-13 16:56:19,275:INFO:Preloading libraries
2023-08-13 16:56:43,807:INFO:Initializing finalize_model()
2023-08-13 16:56:43,807:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-13 16:56:43,809:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-13 16:56:43,950:INFO:Initializing create_model()
2023-08-13 16:56:43,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-13 16:56:43,950:INFO:Checking exceptions
2023-08-13 16:56:43,962:INFO:Importing libraries
2023-08-13 16:56:43,962:INFO:Copying training dataset
2023-08-13 16:56:43,965:INFO:Defining folds
2023-08-13 16:56:43,965:INFO:Declaring metric variables
2023-08-13 16:56:43,965:INFO:Importing untrained model
2023-08-13 16:56:43,965:INFO:Declaring custom model
2023-08-13 16:56:43,965:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-13 16:56:43,965:INFO:Cross validation set to False
2023-08-13 16:56:43,965:INFO:Fitting Model
2023-08-13 16:56:46,596:INFO:[LightGBM] [Info] Number of positive: 283883, number of negative: 283883
2023-08-13 16:56:46,674:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033356 seconds.
2023-08-13 16:56:46,674:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-13 16:56:46,674:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-13 16:56:46,674:INFO:[LightGBM] [Info] Total Bins 4075
2023-08-13 16:56:46,690:INFO:[LightGBM] [Info] Number of data points in the train set: 567766, number of used features: 16
2023-08-13 16:56:46,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-08-13 16:56:50,294:INFO:Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-08-13 16:56:50,294:INFO:create_model() successfully completed......................................
2023-08-13 16:56:50,466:INFO:_master_model_container: 17
2023-08-13 16:56:50,466:INFO:_display_container: 5
2023-08-13 16:56:50,466:INFO:Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-08-13 16:56:50,466:INFO:finalize_model() successfully completed......................................
2023-08-13 16:57:16,824:INFO:Initializing predict_model()
2023-08-13 16:57:16,824:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000255539951B0>)
2023-08-13 16:57:16,825:INFO:Checking exceptions
2023-08-13 16:57:16,825:INFO:Preloading libraries
2023-08-13 16:57:38,814:INFO:Initializing predict_model()
2023-08-13 16:57:38,815:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002555DCD74F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\91772\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['General_Health', 'Checkup',
                                             'Exercise', 'Skin_Cancer',
                                             'Other_Cancer', 'Depression',
                                             'Diabetes', 'Arthritis', 'Sex',
                                             'Age_Category', 'BMI',
                                             'Smoking_History',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegeta...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000255539953F0>)
2023-08-13 16:57:38,815:INFO:Checking exceptions
2023-08-13 16:57:38,816:INFO:Preloading libraries
2023-08-13 16:57:38,819:INFO:Set up data.
2023-08-13 16:57:38,890:INFO:Set up index.
